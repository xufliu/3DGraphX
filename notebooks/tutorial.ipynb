{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98fa13ae",
   "metadata": {},
   "source": [
    "\n",
    "# ThreeGraphX â€” Transductive Explanation Demo (QM9, SchNet/DimeNet++)\n",
    "\n",
    "This tutorial shows an end-to-end **transductive** explanation workflow:\n",
    "\n",
    "1. Load QM9 and a backbone model (SchNet or DimeNet++).\n",
    "2. Visualize the molecule graph with node order and element type.\n",
    "3. Run the transductive explainer to optimize a node mask for this molecule.\n",
    "4. Inspect & visualize the explanation (mask heatmap, explanatory subgraph, clusters).\n",
    "5. (Optional) Evaluate top-k fidelity against the full-model prediction.\n",
    "\n",
    "> **Note:** This notebook assumes you're running from the repo root with the package at `src/threegraphx/`. If not, adapt the `PYTHONPATH` cell accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c30ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If you're running on Google Colab, uncomment the next lines to install dependencies.\n",
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "# !pip install torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
    "# !pip install networkx matplotlib\n",
    "\n",
    "import os, sys, os.path as osp, numpy as np, torch\n",
    "print(\"Torch:\", torch.__version__, \"| CUDA:\", torch.cuda.is_available())\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce914065",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make the local package importable (expects repo layout with src/threegraphx/...)\n",
    "import os, sys, os.path as osp\n",
    "HERE = os.getcwd()\n",
    "SRC = osp.join(HERE, \"src\")\n",
    "if SRC not in sys.path:\n",
    "    sys.path.insert(0, SRC)\n",
    "\n",
    "from torch_geometric.datasets import QM9\n",
    "from torch_geometric.nn import knn_graph\n",
    "from torch_geometric.explain import Explainer, ModelConfig\n",
    "from torch_geometric.nn.models.schnet import SchNet\n",
    "from torch_geometric.nn.models.dimenet import DimeNet, DimeNetPlusPlus\n",
    "\n",
    "# Import our project modules\n",
    "from threegraphx.hooks.base import MaskPoint\n",
    "from threegraphx.hooks.schnet import SchNetHooks\n",
    "from threegraphx.hooks.dimenet import DimeNetHooks\n",
    "from threegraphx.transductive import GraphXTransductive\n",
    "from threegraphx.viz import visualize_graph, visualize_mask, visualize_clusters, visualize_explanatory_subgraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50abee28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Configuration ----\n",
    "BACKBONE = \"schnet\"      # choices: \"schnet\", \"dimenet\"\n",
    "USE_DPP = True           # if BACKBONE == \"dimenet\": True -> DimeNet++, False -> DimeNet\n",
    "TARGET_ATTR = 0          # QM9 property index (0..11). For dimenet path, we remap y accordingly (see below).\n",
    "EPOCHS = 30              # inner steps for transductive optimization\n",
    "LR = 1e-2\n",
    "MASK_POINT = \"embed\"     # \"embed\" or \"pre_agg\" (where to multiply node masks)\n",
    "KNN_K = 2                # build a 2-NN graph over coordinates for clustering\n",
    "SEED = 42\n",
    "\n",
    "torch.manual_seed(SEED); np.random.seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721162bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_schnet_and_data(device: str, data_root: str, target_attr: int):\n",
    "    ds = QM9(data_root)\n",
    "    model, datasets = SchNet.from_qm9_pretrained(data_root, ds, target_attr)\n",
    "    return model.to(device), datasets  # (train, val, test)\n",
    "\n",
    "def split_qm9(dataset, train=2048, val=500, test=1024, seed=42):\n",
    "    from torch.utils.data import random_split\n",
    "    N = len(dataset)\n",
    "    assert train + val + test <= N, \"Requested split larger than dataset\"\n",
    "    g = torch.Generator().manual_seed(seed)\n",
    "    return random_split(dataset, [train, val, test], generator=g)\n",
    "\n",
    "def build_dimenet_and_data(device: str, data_root: str, target_attr: int, use_pp: bool, seed=42):\n",
    "    dataset = QM9(data_root)\n",
    "    # Common DimeNet setup: select 12 targets in specific order:\n",
    "    idx = torch.tensor([0, 1, 2, 3, 4, 5, 6, 12, 13, 14, 15, 11])\n",
    "    dataset.data.y = dataset.data.y[:, idx]\n",
    "    if use_pp:\n",
    "        model = DimeNetPlusPlus(out_channels=1).to(device)\n",
    "    else:\n",
    "        model = DimeNet(out_channels=1).to(device)\n",
    "    train_ds, val_ds, test_ds = split_qm9(dataset, 2048, 500, 1024, seed)\n",
    "    return model, (train_ds, val_ds, test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2963a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_ROOT = os.path.join(HERE, \"data\", \"QM9\")\n",
    "os.makedirs(DATA_ROOT, exist_ok=True)\n",
    "\n",
    "if BACKBONE == \"schnet\":\n",
    "    hooks = SchNetHooks()\n",
    "    model, (train_ds, val_ds, test_ds) = build_schnet_and_data(device, DATA_ROOT, TARGET_ATTR)\n",
    "else:\n",
    "    hooks = DimeNetHooks()\n",
    "    model, (train_ds, val_ds, test_ds) = build_dimenet_and_data(device, DATA_ROOT, TARGET_ATTR, USE_DPP)\n",
    "\n",
    "print(f\"Backbone: {BACKBONE} ({'DimeNet++' if (BACKBONE=='dimenet' and USE_DPP) else ''})\")\n",
    "print(\"Train/Val/Test sizes:\", len(train_ds), len(val_ds), len(test_ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf0c452",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pick a single molecule from the test set\n",
    "data = test_ds[0].to(device)\n",
    "print(\"z shape:\", tuple(data.z.shape), \"| pos shape:\", tuple(data.pos.shape), \"| y shape:\", tuple(data.y.shape))\n",
    "\n",
    "# Build a simple 2-NN graph on positions for clustering and visualization\n",
    "edges = knn_graph(data.pos, k=KNN_K).detach().cpu().numpy()\n",
    "\n",
    "# Visualize the original molecule\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(5.5, 4.8))\n",
    "visualize_graph(z=data.z, pos=data.pos, edge_index=edges, ax=ax, title=\"Molecule (index:symbol)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a148388",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=GraphXTransductive(\n",
    "        hooks=hooks,\n",
    "        epochs=EPOCHS,\n",
    "        lr=LR,\n",
    "        mask_point=MaskPoint.EMBED if MASK_POINT == \"embed\" else MaskPoint.PRE_AGG,\n",
    "    ),\n",
    "    explanation_type=\"phenomenon\",\n",
    "    node_mask_type=\"object\",   # cluster-parameterized node mask\n",
    "    edge_mask_type=None,\n",
    "    model_config=ModelConfig(\n",
    "        mode=\"regression\",\n",
    "        task_level=\"graph\",\n",
    "        return_type=\"raw\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_full = model(data.z, data.pos)[0]\n",
    "\n",
    "explanation = explainer(\n",
    "    x=data.z,\n",
    "    edge_index=data.pos,   # hooks interpret 'edge_index' as 'pos' for molecules\n",
    "    target=data.y[:, 0].double(),\n",
    "    edges=edges,           # for clustering\n",
    ")\n",
    "\n",
    "print(\"Full-model prediction:\", y_full.detach().cpu().numpy().ravel())\n",
    "print(\"Target:\", data.y[:, 0].detach().cpu().numpy().ravel())\n",
    "print(\"Node mask shape:\", tuple(explanation.node_mask.shape))\n",
    "if hasattr(explanation, \"clusters\"):\n",
    "    print(\"Num clusters:\", len(explanation.clusters))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7379210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualize continuous mask and clusters\n",
    "fig, ax = plt.subplots(1, 2, figsize=(11, 4.4))\n",
    "visualize_mask(z=data.z, pos=data.pos, edge_index=edges, mask=explanation.node_mask, threshold=0.6, ax=ax[0], title=\"Node importance (mask)\")\n",
    "if hasattr(explanation, \"clusters\"):\n",
    "    visualize_clusters(z=data.z, pos=data.pos, edge_index=edges, clusters=explanation.clusters, ax=ax[1], title=\"Clusters\")\n",
    "else:\n",
    "    ax[1].axis(\"off\"); ax[1].set_title(\"No clusters available\")\n",
    "plt.show()\n",
    "\n",
    "# Visualize only the explanatory subgraph (above threshold)\n",
    "fig, ax = plt.subplots(figsize=(5.5, 4.8))\n",
    "visualize_explanatory_subgraph(z=data.z, pos=data.pos, edge_index=edges, mask=explanation.node_mask, threshold=0.6, ax=ax, title=\"Explanatory subgraph\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcdc015",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optional: simple top-k fidelity check\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def eval_topk(model, z, pos, node_mask, ks=[2,3,5,8]):\n",
    "    with torch.no_grad():\n",
    "        full = model(z, pos)[0]\n",
    "    m = node_mask.detach().view(-1)\n",
    "    order_nodes = torch.argsort(m, descending=True).tolist()\n",
    "    out = {}\n",
    "    for k in ks:\n",
    "        idx_nodes = sorted(order_nodes[:k])\n",
    "        pred_n = model(z[idx_nodes], pos[idx_nodes])[0]\n",
    "        loss_n = F.l1_loss(pred_n, full).item()\n",
    "        out[k] = {\"nodes\": loss_n}\n",
    "    return out\n",
    "\n",
    "res = eval_topk(model, data.z, data.pos, explanation.node_mask, ks=[2,3,5,8])\n",
    "res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb56517",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
